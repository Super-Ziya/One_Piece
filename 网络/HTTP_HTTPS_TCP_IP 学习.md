## HTTP 学习

> 影响 HTTP 网络请求的因素主要是：带宽和延迟，关键在低延迟
>
> URI 包括 URL（统一资源定位符，像地址） 和 URN（像名字）
>
> URI 是 URL 的关键是协议（protocol），如 http://、ftp://
>
> ps. 下面全是 URI，部分是 URL

```http
ftp://ftp.is.co.za/rfc/rfc1808.txt (URL)
http://www.ietf.org/rfc/rfc2396.txt (URL)
ldap://[2001:db8::7]/c=GB?objectClass?one (URL)
mailto:John.Doe@example.com (URL)
news:comp.infosystems.www.servers.unix (URL)
telnet://192.0.2.16:80/ (URL)
tel:+1-816-555-1212
urn:oasis:names:specification:docbook:dtd:xml:4.1.2
```

- 分层
  - 应用层：HTTP
  - 传输层：TCP、UDP
  - 网络层：IP

---

### 一、响应行

- 无错：
  - 1XX：服务端收到请求，需进一步处理才能完成
    - 100（继续）：服务器已收到请求的第一部分，正在等待其余部分
    - 101（切换协议）：请求者要求服务器切换协议，服务器已确认并准备切换
  - 2XX：成功收到
    - 200（成功）：服务器已处理请求
    - 201（已创建）：请求成功且服务器创建新资源
    - 202（已接受）：服务器已接受请求，但未处理
    - 203（非授权信息）：服务器已处理请求，但返回的信息可能来自另一来源
    - 204（无内容）：服务器已处理请求，但没有返回任何内容
  - 3XX：
    - 301（永久移动）：请求的网页已永久移动到新位置，服务器会自动将请求者转到新位置
    - 302（临时移动）：服务器从不同位置的网页响应请求，但请求者应继续使用原有位置进行以后请求
  
- 出错：
  - 4XX：客户端出错
    - 400（错误请求）：语法错误，服务器无法理解请求（传参格式不正确）
    - 401（未授权）：请求需要验证
    - 403（禁止）：服务器接受到请求，但拒绝处理
    - 404（未找到）：服务器找不到请求的网页
  - 5XX：服务端出错
    - 500（内部错误）：服务器内部错误（传参格式不正确）
    - 502（错误网关）：服务器作为网关或代理，从上游服务器拿不到响应
    - 503（服务不可用）：服务器暂时无法使用（超载、停机维护）
    - 504（网关超时）：服务器作为网关或代理，没有及时从上游服务器获取响应
    - 505（HTTP 版本不被支持）：服务器不支持请求所用的 HTTP 版本
  
- HTTP 请求消息头

  ```http
  1 GET /simple.htm HTTP/1.1<CR>
  2 Accept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, application/x-shockwave-flash, application/vnd.ms-excel, application/vnd.ms-powerpoint, application/msword, */*<CR>
  3 Accept-Language: zh-cn<CR>
  4 Accept-Encoding: gzip, deflate<CR>
  5 User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)<CR>
  6 Host: localhost:8080<CR>
  7 Connection: Keep-Alive<CR>
  8 <CR>
  ```

  - 第一行：HTTP 请求格式（POST（有消息体）、GET）
  - 第二行：浏览器能接受的 Content-type
  - 第三、四行：语言与编码
  - 第五行：本机相关信息（浏览器类型、操作系统信息）
  - 第六行：请求的主机和端口
  - 第七行：连接方式，Keep-Alive 表示长连接

- HTTP 应答消息头

  ```http
  1 HTTP/1.1 200 OK<CR>
  2 Server: Microsoft-IIS/5.1<CR>
  3 X-Powered-By: ASP.NET<CR>
  4 Date: Fri, 03 Mar 2006 06:34:03 GMT<CR>
  5 Content-Type: text/html<CR>
  6 Accept-Ranges: bytes<CR>
  7 Last-Modified: Fri, 03 Mar 2006 06:33:18 GMT<CR>
  8 ETag: "5ca4f75b8c3ec61:9ee"<CR>
  9 Content-Length: 37<CR>
  10 <CR>
  11 <html><body>hello world</body></html>
  ```

  - 第一行：HTTP 协议版本，HTTP 返回码
  - 第二行：服务器使用的服务软件
  - 第三行：附加提示
  - 第四行：处理请求的时间
  - 第五行：返回消息的 content-type（HTML、jpeg）
  - 第九行：消息体的长度

### 二、HTTP1.0 和 HTTP1.1 的区别

- 长连接

  > HTTP1.1 支持长连接和请求的流水线处理，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少建立和关闭连接的消耗和延迟，在 HTTP1.1 中**默认开启**长连接
  >
  > 管道化：将多条请求放入队列，第一条请求发送时，之后的请求也可发送，但响应需按顺序（请求和响应无序号），客户端保持未收到响应的请求，当连接中断时需重发请求，幂等的请求（GET、HEAD）才能管道化

- 节约带宽

  > HTTP1.0 中存在一些浪费带宽的现象，如客户端只需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持**断点续传**功能。HTTP1.1 支持**只发送 header** 信息（不带任何 body 信息），如果服务器认为客户端有权限请求服务器，则返回 100，客户端接收到 100 才开始把请求 body 发送到服务器；如果返回 401，客户端就可以不用发送请求 body 节约带宽

- HOST 域

  > HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此请求消息中的 URL 并没有传递主机名（hostname），**HTTP1.0 没有 host 域**。而一台物理服务器上可以存在**多个虚拟主机**，且共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都支持 host 域，且请求消息中如果没有 host 域会报错（400）

- 缓存处理

  > HTTP1.0 中主要使用 header 里的 If-Modified-Since，Expires 来做为缓存判断的标准，HTTP1.1 引入更多缓存控制策略例如 Entity tag，If-Unmodified-Since，If-Match，If-None-Match 等缓存头来控制缓存策略

- 错误通知管理

  > HTTP1.1 中新增了 24个 错误状态响应码

#### 1、HTTP 1.1 缺陷

- 高延迟（HTTP 队头阻塞）
  - TCP 队头阻塞：一个 TCP 分节丢失，导致其后续分节不按序到达接收端时，该后续分节被接收端一直保持直到丢失的第一个分节重传到达接收端，后续分节延迟递送确保接收进程能按照发送端的发送顺序接收数据
  - HTTP 队头阻塞：管道化要求服务端必须按请求发送顺序返回响应，如果响应返回延迟，其后续响应都被延迟直到队头响应送达
- 无状态特性：对连接状态无记忆能力，无 cookie 机制
- 明文传输（不安全性）
- 不支持服务端推送

### 三、HTTPS 和 HTTP 的区别

- HTTPS 协议需要到 CA 申请证书
- HTTP 协议运行在 TCP 之上，传输内容是明文，HTTPS 运行在 SSL/TLS 之上，SSL/TLS 运行在 TCP 之上，传输内容经过加密
- 连接方式不同，用的端口也不一样，HTTP 是 80，HTTPS 是 443
- HTTPS 可以有效防止运营商劫持

### 四、SPDY

> HTTP1.x 的优化
>
> SPDY 位于 HTTP 之下，TCP 和 SSL 之上

<img src="图片.assets\SPDY位置.png" alt="SPDY位置" style="zoom: 50%;" />

- 降低延迟

  > 采取多路复用，多个请求共享一个 tcp 连接，解决 HOL blocking（线头阻塞）问题，降低延迟，提高带宽利用率
  >
  > HOL blocking（线头阻塞）：当前 1、3 输入队列是相互竞争，向相同输出端口 4 发送数据包。如果交换结构决定从输入队列 3 中传输数据包，则同时不能处理输入队列 1 的数据包，且输出队列 1 的后续数据包，如第二个数据包（输出端口 3，当前空闲）也将无法被输出到端口 3

  ![线头阻塞](图片.assets\线头阻塞.png)

  

- 请求优先级

  > SPDY 允许给每个 request 设置优先级，重要请求会优先得到响应。如浏览器加载首页，首页的 html 内容应优先展示，之后才是各种静态资源文件，脚本文件等加载，保证用户第一时间看到网页内容

- header 压缩

  > HTTP1.x 的 header 很多时候是重复多余的。选择合适的压缩算法可以减小包大小和数量

- 基于 HTTPS 的加密协议传输

- 服务端推送

  > 如网页有个 sytle.css 请求，客户端收到 sytle.css 数据时，服务端将 sytle.js 文件推送给客户端，当客户端再次尝试获取 sytle.js 时可以直接从缓存中获取，不用再发请求
  >
  > 普通：
  >
  > <img src="图片.assets\普通客户端请求.png" alt="普通客户端请求" style="zoom:67%;" />
  >
  > 服务端推送：
  >
  > <img src="图片.assets\服务器推送.png" alt="服务器推送" style="zoom:67%;" />

### 五、HTTP2.0 和 SPDY 的区别

- HTTP2.0 支持明文 HTTP 传输，SPDY 强制使用 HTTPS
- HTTP2.0 消息头的压缩算法采用 HPACK，SPDY 采用的 DEFLATE

### 六、HTTP2.0 和 HTTP1.X 的区别

- 二进制协议

  > HTTP2是基于二进制“帧”的协议，HTTP1.1是基于“文本分割”解析的协议，文本的表现形式有多样性，要做到健壮性考虑的场景很多，二进制只认 0 和 1 的组合，实现方便且健壮

  - 文本格式：以换行符分割每一条key:value的内容，解析速度慢且容易出错。“服务端”要不断读入字节直到遇到分隔符（换行符，代码中可能使用/n或/r/n表示），问题：

    - 一次只能处理一个请求或响应，因为在完成之前不能停止解析（字符必须按顺序传送）
    - 无法预知需要多少内存，这会带给“服务端”很大的压力，因为不知道要把一行要解析的内容读到多大的“缓冲区”中，在保证解析效率和速度的前提下，内存该如何分配

  - 二进制帧：前9个字节对每个帧都是一致的，“服务器”只需解析这些字节，就知道整个帧期望多少字节数来进行处理，对二进制帧进行顺序标识，不会出现乱序

    | 名称              | 长度   | 描述                                 |
    | :---------------- | :----- | :----------------------------------- |
    | Length            | 3 字节 | 帧负载长度，默认最大帧大小2^14       |
    | Type              | 1 字节 | 当前帧的类型                         |
    | Flags             | 1 字节 | 具体帧的标识                         |
    | R                 | 1 字节 | 保留位，不需要设置                   |
    | Stream Identifier | 31 位  | 每个流的唯一ID                       |
    | Frame Payload     | 不固定 | 真实帧的长度，真实长度在Length中设置 |

- 多路复用

  > 连接共享，一个 request 对应一个 id，一个连接上可以有多个 request，每个连接的 request 可以随机的混杂在一起，接收方可以根据request的 id 将 request 再归属到各自不同的服务端请求里面。

- header 压缩

  > HTTP1.x 的 header 带有大量信息，每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields 表，避免重复 header 的传输，减小传输大小

  - http 请求和响应由状态行、请求/响应头部、消息主题三部分组成的。 一般消息主体都会经过 gzip 压缩，或本身传输的是压缩后的二进制文件（如图片、音频等），但状态行和头部多是没有经过任何压缩，而是直接以纯文本的方式进行传输的。随着请求数量越来越多，头部的流量越来越多，且在建立初次链接后的链接也要发送 user-agent 等信息，是一种浪费

  - 头部压缩需要在支持 HTTP/2 的浏览器和服务端之间：

    - 维护一份相同的静态字典（Static Table），包含常见的头部名称，及常见的头部名称与值的组合

      > 作用：
      >
      > 对完全匹配的头部键值对，如 `:method: GET`，可直接使用一个字符表示
      >
      > 对头部名称可以匹配的键值对，如 `cookie: xxxxxxx`，可将名称使用一个字符表示

    - 维护一份相同的动态字典（Dynamic Table），可以动态地添加内容

    - 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）

- 服务端推送

  > 同 SPDY 一样

### 七、HTTP2.0 多路复用和 HTTP1.X 长连接复用的区别

- HTTP/1.* 一次请求响应，建立一个连接，用完关闭，每一个请求都要建立一个连接
- HTTP/1.1 Pipeling 解决方式：若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞即线头阻塞
- HTTP/2 多个请求可同时在一个连接上并行执行，请求之间不会互相影响

<img src="图片.assets\http1、2区别.png" alt="http1、2区别" style="zoom: 67%;" />

#### 1、HTTP2 缺陷

- TCP 以及 TCP+TLS 建立连接的延时
- TCP 队头阻塞没有彻底解决
- 多路复用导致服务器压力上升
- 多路复用容易 Timeout

### 八、HTTPS

####1、密码学基础

- 明文： 未被加密过的原始数据
- 密文：明文被某种加密算法加密之后，会变成密文，确保原始数据的安全。密文也可被解密，得到原始的明文
- 密钥：在明文转换为密文或将密文转换为明文的算法中输入的一种参数。密钥分为对称密钥与非对称密钥，分别应用在对称加密和非对称加密上
- 对称加密（私钥加密）：信息的发送方和接收方使用同一个密钥去加密和解密数据。特点是算法公开、加解密速度快，适合大数据量，常见的对称加密算法有 DES、3DES、TDEA、Blowfish、RC5 和 IDEA

> 加密过程：
> 明文 + 加密算法 + 私钥 => 密文，
> 解密过程：
> 密文 + 解密算法 + 私钥 => 明文，
> 对称加密中用到的密钥叫做私钥，该密钥不能被泄露。其加密过程中的私钥与解密过程中用到的私钥是同一个密钥，这是加密“对称”的原因。由于对称加密的算法公开，一旦私钥泄露，密文就容易被破解，对称加密的缺点是密钥安全管理困难

- 非对称加密（公钥加密）：与对称加密相比，安全性更好。非对称加密使用一对密钥（公钥和私钥），二者成对出现。私钥自己保存，不能对外泄露。公钥是公共的密钥，任何人都可获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密

> 被公钥加密过的密文只能被私钥解密，过程：
> 明文 + 加密算法 + 公钥 => 密文； 密文 + 解密算法 + 私钥 => 明文，
> 被私钥加密过的密文只能被公钥解密，过程：
> 明文 + 加密算法 + 私钥 => 密文； 密文 + 解密算法 + 公钥 => 明文，
> 加解密使用两个不同密钥，这是加密“非对称”的原因。非对称加密的缺点是加解密时间长、速度慢，适合少量数据。非对称加密中的主要算法有：RSA、Elgamal、Rabin、D-H、ECC（椭圆曲线加密算法）等

------

####2、HTTPS通信过程

- HTTPS 协议 = HTTP 协议 + SSL/TLS 协议，在数据传输中，用 SSL/TLS 对数据进行加解密，用 HTTP 对加密后的数据进行传输
- SSL（Secure Sockets Layer，安全套接层协议），是为网络通信提供安全及数据完整性的一种安全协议
- TLS（Transport Layer Security，安全传输层协议），TLS 与 SSL3.0 间存在着显著差别，主要是其支持的加密算法不同，所以 TLS 与 SSL3.0 不能互操作
- HTTPS 为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输

![https通信](图片.assets\https通信.png)

- HTTPS 在传输的过程中会涉及到三个密钥：

> 服务器端的公钥和私钥，用来进行非对称加密
>
> 客户端生成的随机密钥，用来进行对称加密

- HTTPS 请求：
  - 客户端向服务器发起 HTTPS 请求，连接到服务器的 443 端口，发送 Client Hello 消息：

    - 一个客户端生成的随机数 Random1
    - 客户端支持的加密组件列表（Ciphers Suites，所使用的加密算法及密钥长度等）
    - SSL Version
    - 压缩算法（压缩 Http 头部）等

  - 服务器端接收到 Client Hello 后发送 Server Hello 消息

    - 从客户端传来的消息中确定一种加密组件（决定加密和生成摘要时使用的算法）
    - 生成随机数 Random2（用来创建加密密钥）
    - 如果支持则同意客户端首选的压缩算法
    - 选择客户端支持的 SSL 最新版本

    > 此时客户端知道：
    >
    > SSL 版本、密钥交换、信息验证、加密算法、压缩方法、两个随机数

  - 服务器发送：

    - Certificate 消息（可选）：数字证书和到根 CA 整个链，使客户端能用服务器证书中的**服务器公钥**认证服务器
    - 服务器密钥交换（可选）：在 Client Hello 消息的 Cipher Suite 信息决定密钥交换方式（RSA 或 DH），在此处包含完成密钥交换所需的一系列参数
    - 证书请求（可选）：要求客户自身进行验证，包含服务端支持的证书类型（RSA、DSA、ECDSA）和服务器端信任的所有 CA 列表，客户端用来筛选证书
    - 服务器握手完成：第二阶段的结束，第三阶段开始的信号

  - 客户端接收并解析，发送响应消息：

    - Certificate 消息（可选）：若服务器端要求发送客户端证书则发送，若没有证书发送一个 no_certificate 警告

    - 客户机密钥交换（Pre-master-secret）：根据随机数，按照密钥交换算法算出一个 pre-master（随机数）发送给服务器，服务器端收到后算出 main master（密钥），客户端也能算出 main master，如此双方算出对称密钥。发送过程使用服务器公钥加密，服务器用自己私钥解密（客户端证明自己持有客户端证书私钥）

      > RSA 算法生成一个 48 字节的随机数
      >
      > DH 算法发送客户端 DH 参数

    - 证书验证（可选）：在客户端发送自己证书到服务器端才需发送。包含一个签名，对从第一条消息以来的所有握手消息的 HMAC 值（用密钥）进行签名

  - 客户端发送一个 ChangeCipherSpec 消息（编码改变通知，ChangeCipherSpec 是一个独立协议）

    - 把协商的加密套件拷贝到当前连接状态中
  
- 客户端用新算法、密钥参数发送一个 Finished 消息，包含连接至今全部报文的整体校验值（也就是HASH值），检查密钥交换和认证过程是否成功（使用 HMAC 算法计算收到和发送的所有握手消息的摘要，通过 RFC5246 定义的伪函数 PRF 计算出结果，加密后发送）
  
- 服务器同样发送 ChangeCipherSpec 消息和 Finished 消息
  
    - 用私钥解密得 Pre-master 数据，基于两个明文随机数计算得协商密钥
    - 计算之前所有接收信息的 hash 值，解密客户端发送的 hash 值，验证数据和密钥正确性
    - 发送一个 ChangeCipherSpec（告知客户端已经切换到协商过的加密套件状态，准备使用加密套件和 Session Secret 加密数据）
    - 用 Session Secret 加密一段 Finish 消息发送给客户端，验证之前通过握手建立起来的加解密通道是否成功
  
- 三个随机数

  - 对于客户端：生成 Pre-master secret 后，结合之前两个随机数，用加密算法算出 master secret，根据其推导出 hash secret 和 session secret
  - 对于服务端：解密获得 Pre-master secret 后，结合之前两个随机数，用加密算法算出 master secret，根据其推导出 hash secret 和 session secret
  - 客户端和服务端的 master secret 依据三个随机数推导出来，不会在网络上传输的，只有双方知道，不会有第三者知道，同时推导出来的 session secret 和 hash secret 与服务端一样
  - 需要随机数生成的密钥才不会每次都一样，由于 SSL 协议中证书是静态的，有必要引入随机因素保证协商密钥的随机性。对于 RSA 密钥交换算法，pre-master secret 本身是随机数，再加上之前两个随机数，三个随机数通过一个密钥导出器最终导出一个对称密钥。pre-master secret 的存在在于 SSL 协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，pre-mastersecret 有可能被猜出来，仅用 pre-master secret 作为密钥不合适，客户端和服务器加上 pre-master secret 三个随机数一同生成的密钥就不易被猜出了，一个伪随机可能完全不随机，三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一

------

####3、数字证书

- 服务器接收到客户端发来的请求时，会向客户端发送服务器自己的公钥，但黑客有可能中途篡改公钥，将其改成黑客自己的，这时需要用到数字证书
- 想让客户端信赖公钥，公钥要找一个担保人——证书认证中心（Certificate Authority，简称 CA）。CA 是专门对公钥进行认证、担保的公司。 全球知名的 CA 也就 100 多个，都是全球都认可的，比如 VeriSign、GlobalSign 等，国内知名的 CA 有 WoSign
- CA 本身也有一对公钥和私钥，CA 会用自己的私钥对要进行认证的公钥进行非对称加密，此处待认证的公钥就相当于是明文，加密完之后，得到的密文再加上证书的过期时间、颁发给、颁发者等信息，组成数字证书
- 不论什么平台，设备的操作系统中都会内置 100 多个全球公认的 CA，即中存储了这些 CA 的公钥。当客户端接收到服务器的数字证书的时候，会进行如下验证：

> 客户端用设备中内置的 CA 的公钥尝试解密数字证书，如果所有内置的 CA 的公钥都无法解密该数字证书，说明该数字证书不是由一个全球知名的 CA 签发的，这样客户端无法信任该服务器的数字证书
>
> 如果有一个 CA 的公钥能够成功解密该数字证书，说明该数字证书就是由该 CA 的私钥签发的，因为被私钥加密的密文只能被与其成对的公钥解密
>
> 此外还要检查客户端当前访问的服务器的域名是否与数字证书中提供的“颁发给”这一项吻合，还要检查数字证书是否过期等

- 证书链：一般情况下，CA 不会用自己的私钥去直接签名某网站的数字证书，一般 CA 会先签发一种证书，然后用这种证书再去签发百度等的数字证书。如 VeriSign 签发 Symantec 证书，然后 Symantec 又签发baidu.com，VeriSign 位于最顶端，类似根结点，叫做根 CA，Symatec 位于中间，叫做中间 CA，有可能有多个中间CA，这样从根 CA 到中间 CA，再到最终网站的证书，形成一条证书链

### 九、TCP

> https://mp.weixin.qq.com/s/HjOUsKn8eLfDogbBX3hPnA

- TCP 与 UDP 的区别
  - TCP 面向连接，发送数据前需要建立连接，UDP 是无连接的

  - TCP 面向字节流，将数据看成字节流，UDP 面向报文

  - TCP 提供可靠服务，无差错，不丢失，不重复，按序到达；UDP 尽最大努力交付，不可靠

  - TCP 传输效率较低（Http，Ftp）；UDP传输效率高（视频、电话）

  - TCP 是一对一，UDP 支持一对一、一对多、多对多

  - 报文首部不同：

    - TCP：

    ![TCP 报文](图片.assets\TCP 报文.png)

    - UDP：

      ![UDP 报文](图片.assets\UDP 报文.jpg)

- TCP 三次握手：

  <img src="图片.assets\三次握手.png" alt="三次握手"  />

  - 客户端向服务器发出连接请求报文，报文首部中的同步位 SYN=1，同时随机生成初始序列号 seq=x
  - 服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中 ACK=1，SYN=1，确认号是 ack=x+1，同时为自己随机初始化一个序列号 seq=y
  - 客户进程收到确认后，还要向服务器给出确认。确认报文的 ACK=1，ack=y+1，此时TCP连接建立

- TCP 四次挥手：

  > 为什么挥手四次：
  >
  > 挥手阶段中服务端的 ACK 和 FIN 数据包不能合为一次，因为挥手阶段客户端发送 FIN 表示自己发完了，此时客户端到服务端的连接已经释放，客户端不会再发送数据，但服务端还可以继续向客户端发送数据，等到服务端也完成了数据发送，才会发送 FIN，这时客户端回复 ACK 才可以结束通信

  <img src="图片.assets\四次挥手.png" alt="四次挥手" style="zoom: 80%;" />

  - 客户端发送一个**FIN(结束)**，用来关闭客户到服务端的连接，FIN=1，其序列号为 seq=u
  - 服务端收到 FIN，发回一个**ACK(确认)**，确认收到序号为收到序号 +1，ACK=1，ack=u+1，并且带上自己的序列号 seq=v
  - 服务端发送一个**FIN(结束)**到客户端，服务端关闭客户端的连接。FIN=1，ack=u+1
  - 客户端发送**ACK(确认)**报文确认，并将确认的序号+1，关闭完成。ACK=1，ack=w+1，序列号是 seq=u+1
  - 客户端等待 2MSL（TCP 报文在网络中最长存活时间）时间：如果服务器端没有收到第四次握手，要超时重传，2MSL 是极端时间

- 流量控制：滑动窗口
  - 问题：双方通信时，发送方速率与接收方速率不一定相等，如果发送方速率太快会导致接收方处理不过来，这时只能把处理不过来的数据存在缓存区里（失序的数据包也会被存放在缓存区里，缓存区满了就会丢掉）

  - 设置：

    - TCP/IP 支持全双工传输，通信双方都拥有两个滑动窗口
    - 接收方每次收到数据包，在发送确定报文时告诉发送方自己的缓存区剩余多少空闲（接收窗口大小，用 win 表示），发送方收到后调整发送速率（发送窗口大小），当接收窗口为 0 时，发送方停止发送数据，防止大量丢包
    - 一般接收窗口 >= 发送窗口

  - 策略：

    - 当接收方处理好数据，接受窗口 win > 0 时，接收方发通知报文通知发送方，告诉可继续发送数据；当发送方收到窗口大于 0 的报文时继续发送数据

      > 缺点：假如接收方发送的通知报文由于网络原因丢失，这时双方互相等待

    - 解决：当发送方收到接受窗口 win = 0 时停止发送报文，同时开启定时器，每隔一段时间发个测试报文询问接收方，接收方告诉此时接受窗口大小，如果还是为 0，则发送方再次刷新启动定时器

- 拥塞控制

  > 发送方维护一个拥塞窗口，取决于网络拥堵程度动态变化，发送方将拥塞窗口当作发送窗口 cwnd
  >
  > 维护一个慢开始门限 ssthresh 状态变量
  - 慢开始：当 cwnd < ssthresh 使用慢开始算法，tcp 双方建立连接时 cwnd 是 1，每个传输轮次（一次往返，时间 RTT）指数增长（2 的 n 次幂）
  - 拥塞控制：当 cwnd > ssthresh 使用慢开始算法，每个传输轮次线性加 1，发生拥堵就将 ssthresh 设为当前值的一半，使用慢开始算法
    - 当报文段丢失但网络不拥堵，使用拥塞控制降低效率
  - 快重传：报文丢失时，发送方可继续发送接下来的报文段，当发送端收到累计 3 个连续针对同一个报文段的重复确认，立即重传该序号的下一个报文段
  - 快恢复：快重传后此时知道只是丢失部分报文段，将 ssthresh 设为当前值的一半后，使用拥塞控制算法（如果在慢开始阶段发送块重传会将 ssthresh 设为当前值的一半后，使用慢开始算法）
  
- SACK

  ![SACK](图片.assets\SACK.png)

  - 问题：快重传和超时重传后发送端不知道丢包后的数据有无传输成功

  - SACK 是 TCP 一个选项，允许 TCP 单独确认非连续片段，告知真正丢失的包，只重传丢失片段，使用时必须两个设备都支持 SACK

  - SACK option：

    - 标识是否支持 SACK：Kind = 4，Length = 2

      > 只允许在有 SYN 标志的 TCP 包中（TCP 握手前两个包中），分别表示是否支持 SACK

    - 具体 SACK 信息：Kind = 5，Length 可变，由于 TCP option 不超过 40 字节，最多只有 4 组边界值

    ![TCP_SACK选项](图片.assets\TCP_SACK选项.jpg)

  - 接收方 ACK 规则

    - 第一个 block 需指出哪个 segment 触发 SACK option，才会导致 SACK
    - 尽可能多的把所有的 block 填满
    - SACK 报告最近接收的不连续数据块

  - 接收端行为

    - 数据没有被确认前都保持在滑动窗口内
    - 每个数据包都有一个 SACKed 标志，对已标示的 segment，重新发送会忽略
    - 如果 SACK 丢失，超时重传后重置所有数据包 SACKed 标志

- D-SACK

  ![DSACK](图片.assets\DSACK.png)

  - D-SACK 使用 SACK 告诉发送方哪些数据被重复接收，SACK option 第一个 block 代表被重复发送的序列片段
    - D-SACK 仅是接收端报告一个重复的连续片段
    - 每个重复连续片段只在一个 block 中
    - 重复片段的序列号
    - 第二个 block 指的是 data 没有被确认的

- 半连接 & 全连接

  ![半连接&全连接](图片.assets\半连接&全连接.png)

  - syns queue（半连接队列）

    - Linux 默认队列大小 1024
    - 服务端发送 SYN_ACK 后会开启一个定时器，如果超时没收到客户端的 ACK，将重发 SYN_ACK 包。重传次数默认 5 次

  - accept queue（全连接队列）

    - 使用 listen 函数时，内核会根据传入的 backlog 参数与系统参数 somaxconn 比较取较小值。
    - Nginx 和 Redis 默认的 backlog 值为 511，Linux 默认为 128，Java 默认为 50
    - 默认情况下，全连接队列满以后，服务端会忽略客户端的 ACK，随后重传 SYN+ACK，也可修改这种行为
    - tcp_abort_on_overflow 为 0 表示三次握手最后一步全连接队列满后，服务端会丢掉客户端发过来的ACK，随后重传 SYN+ACK，为 1 表示全连接队列满后，服务端发送 RST 给客户端，直接释放资源

  - 三次握手

    - server 收到 client 的 syn 后，把相关信息放到半连接队列中
    - 回复 syn+ack 给 client
    - server 收到 client 的 ack，如果这时全连接队列没满，从半连接队列拿出相关信息放入全连接队列中，否则按 tcp_abort_on_overflow 指示执行。如果全连接队列满且 tcp_abort_on_overflow 是 0，server 过一段时间再次发送 syn+ack 给 client（重走握手第二步），如果 client 超时等待比较短就容易异常

  - sync flood 攻击：针对半连接队列，攻击方不停建连接，但只做第一步，第二步中攻击方收到 server 的 syn+ack 后故意扔掉导致 server 上该队列满，其它请求无法进来

    - 预防：SYN Cookie 技术，服务器收到 SYN 包返回 SYN + ACK 包时，不分配一个专门的数据区，而是根据 SYN 包计算一个 cookie 值，作为返回 SYN ACK 包的初始序列号，当客户端返回一个 ACK 包时，根据包头信息计算 cookie，与返回的确认序列号（初始序列号 + 1）对比，相同则是一个正常连接，然后分配资源，建立连接

      >  缺点：cookie 计算只涉及包头部分信息，建立连接在服务端不保存任何信息，失去超时重传等功能，计算 cookie 有延迟时间

### 十、HTTP3 QUIC

<img src="图片.assets\http1、2、3.jpg" alt="http1、2、3" style="zoom: 50%;" />

- 相比 HTTP2+TCP+TLS：
  - 减少 TCP 三次握手及 TLS 握手时间
  - 改进的拥塞控制
  - 避免队头阻塞的多路复用
  - 连接迁移
  - 前向冗余纠错
- 矛盾
  - 协议历史悠久导致中间设备僵化，如有些防火墙只允许通过 80 和 443，不放通其他端口
  - 依赖于操作系统的实现导致协议本身僵化
  - 建立连接的握手延迟大
    - TCP 三次握手的延迟
    - TLS 完全握手需要至少 2 个 RTT，简化握手需要 1 个 RTT 的握手延迟
  - 队头阻塞
    - TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理
    - TLS 协议都是按照 record 来处理数据，如果一个 record 中丢失数据，会导致整个 record 无法正确处理

#### 1、特性

- 连接建立延时低

  - 0RTT 建连
    - 传输层 0RTT 就能建立连接
    - 加密层 0RTT 就能建立加密连接

  ![img](https://upload-images.jianshu.io/upload_images/3476718-2160180a0cb063d1)

- 改进的拥塞控制

  - TCP：慢启动，拥塞避免，快重传，快恢复

  - QUIC 默认使用 TCP 的 Cubic 拥塞控制算法 ，也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法

    - 可插拔：能非常灵活地生效，变更和停止

      > 应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。TCP 拥塞控制必须要端到端的网络协议栈支持才能实现。而内核和操作系统的部署成本非常高，升级周期很长
      >
      > 单个应用程序的不同连接也能配置不同的拥塞控制
      >
      > 应用程序不需停机和升级就能实现拥塞控制的变更

  ---

  - TCP：为了保证可靠性，使用基于字节序号的 Sequence Number 及 Ack 来确认消息的有序到达

  - QUIC 使用 Packet Number 代替 Sequence Number，且每个 Packet Number 都严格递增，就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 是一个比 N 大的值，TCP 重传 segment 的 sequence number 和原始保持不变，造成 Tcp 重传的歧义问题：不好判断 RTT

    ![img](https://upload-images.jianshu.io/upload_images/3476718-3b46b4072eabab0c)

    ![img](https://upload-images.jianshu.io/upload_images/3476718-4501c6958d1c8ac3)

  - QUIC 还引入 Stream Offset，即一个 Stream 可以经过多个 Packet 传输，Packet Number 严格递增，没有依赖。但 Packet 里的 Payload 如果是 Stream ，需要依靠 Stream 的 Offset 保证应用数据的顺序。假设 Packet N 丢失，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可将 Stream x 和 Stream x+y 按顺序组织起来交给应用程序处理

    ![img](https://upload-images.jianshu.io/upload_images/3476718-ebca6710bcf15695)

- 不允许 Reneging（接收方丢弃已经接收并且上报给 SACK 选项的内容）

  - TCP 不鼓励，但协议层面允许。考虑到服务器资源有限，如 Buffer 溢出、内存不够等
  - Reneging 对数据重传产生很大的干扰。因为 Sack 表明接收到，但接收端事实上丢弃了该数据
  - QUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰

- 更多的 Ack 块

  - TCP 的 Sack 告诉发送方已经接收到的连续 Segment 的范围，方便发送方选择性重传，由于 TCP 头部最大只有 60 字节，标准头部占用 20 字节，Tcp Option 最大长度只有 40 字节，再加上 Tcp Timestamp option 占用 10 字节，留给 Sack 选项只有 30 字节
  - 每一个 Sack Block 长度是 8 个，加上 Sack Option 头部 2 个字节，Tcp Sack Option 最大只能提供 3 个 Block
  - Quic Ack Frame 可以同时提供 256 个 Ack Block，在丢包率比较高的网络下，更多的 Sack Block 可以提升网络的恢复速度，减少重传量

- Ack Delay 时间

  - Tcp 的 Timestamp 选项只是回显了发送方的时间戳，没有计算接收端接收到 segment 到发送 Ack 该 segment 的时间（Ack Delay），导致 RTT 计算误差，RTT = timeStamp2 - timeStamp1

  - QUIC：RTT = timeStamp2 - timeStamp1 - Ack Delay

    ![img](https://upload-images.jianshu.io/upload_images/3476718-70e17098039397e2)

- 基于 Stream 和 Connection 级别的流量控制

  - QUIC 的流量控制类似 HTTP2，即在 Connection 和 Stream 级别提供了两种流量控制，因为 QUIC 支持多路复用，在一条 Connetion 上会同时存在多条 Stream。既需要对单个 Stream 进行控制，又需要针对所有 Stream 进行总体控制

    - Stream 可认为是一条 HTTP 请求，可用窗口 = 最大窗口数 - 接收到的最大偏移量
    - Connection 可类比一条 TCP 连接，可用窗口 = stream1 可用窗口 + stream2 可用窗口 + streamN 可用窗口

  - QUIC 流量控制

    - 通过 window_update 帧告诉对端自己可以接收的字节数，发送方就不会发送超过这个数量的数据
    - 通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据
    - QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数，如果中间出现丢包，就算接收到更大序号的 Segment，窗口也无法超过这个序列号；QUIC 就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数

    ![img](https://upload-images.jianshu.io/upload_images/3476718-25eb51669327ea30)

- 无队头阻塞的多路复用

  - QUIC 的多路复用和 HTTP2 类似。在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (stream)

  - QUIC 一个连接上的多个 stream 间没有依赖。如 stream2 丢了一个 udp packet，只影响 stream2 的处理，不影响 stream2 前及之后的 stream 的处理

  - HTTP2 的 TCP 队头阻塞：

    ![img](https://upload-images.jianshu.io/upload_images/3476718-e11f888d0d3f8046)

  - HTTP2 强制 TLS，TLS 队头阻塞：Record 是 TLS 协议处理的最小单位，不超过 16K，由于一个 record 必须经过数据一致性校验才能进行加解密，所以一个 16K 的 record，就算丢了一个字节，也会导致已经接收到的 15.99K 数据无法处理，因为不完整

    ![img](https://upload-images.jianshu.io/upload_images/3476718-caf6f05b2efa7756)

  - QUIC：

    - 最基本的传输单元是 Packet，不超过 MTU（最大传输单元），整个加密和认证过程基于 Packet，不跨越多个 Packet，避免 TLS 协议队头阻塞
    - Stream 间相互独立，如 Stream2 丢了一个 Pakcet，不影响 Stream3 和 Stream4，不存在 TCP 队头阻塞

    ![img](https://upload-images.jianshu.io/upload_images/3476718-28f763ea0ee73de3)

  ---

  - TCP 协议头部没有经过任何加密和认证，在传输过程中很容易被中间网络设备篡改，注入和窃听。如修改序列号、滑动窗口

  - QUIC 的 packet 除了个别报文如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的，只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险

    （红色是 Stream Frame 报文头部，有认证、绿色是报文内容，加密）

    ![img](https://upload-images.jianshu.io/upload_images/3476718-c5c5eda1292e415b)

- 连接迁移

  - 连接迁移：当其中任一个元素变化时，这条连接依然维持着，能够保持业务逻辑不中断，如手机在 WIFI 和 4G 移动网络切换时，客户端的 IP 肯定发生变化，需要重新建立和服务端的 TCP 连接，从 TCP 连接角度无解
  - TCP 连接由四元组标识（源 IP，源端口，目的 IP，目的端口）
  - QUIC 连接不以 IP 及端口四元组标识，以一个 64 位的随机数作为 ID 来标识，就算 IP 或者端口发生变化，只要 ID 不变，连接依然维持着，上层业务逻辑感知不到变化，不中断，不重连
  - ID 是客户端随机产生的，长度 64 位，冲突概率非常低

- 其他

  - QUIC 还实现前向冗余纠错，在重要的包如握手消息发生丢失时，能够根据冗余信息还原出握手消息
  - QUIC 还实现证书压缩，减少证书传输量，针对包头进行验证等

### 十一、SSL

- 握手协议

  ![img](https://img-blog.csdn.net/20180523150126935)

  - 建立安全能力：SSL握手的第一阶段启动逻辑连接，建立这个连接的安全能力。首先客户机向服务器发出client hello消息并等待服务器响应，随后服务器向客户机返回server hello消息，对client hello消息中的信息进行确认。

    - 客户发送CilentHello信息，包含：

      （1）客户端可以支持的SSL最高版本号

      （2）一个用于生成主密钥的32字节的随机数

      （3）一个确定会话的会话ID

      （4）一个客户端可以支持的密码套件列表：每个套件都以“SSL”开头，紧跟着的是密钥交换算法。用“With”把密钥交换算法、加密算法、散列算法分开

      （5）一个客户端可以支持的压缩算法列表

    - 服务器用ServerHello信息应答客户，包括：

      （1）一个SSL版本号。取客户端支持的最高版本号和服务端支持的最高版本号中的较低者

      （2）一个用于生成主密钥的32字节的随机数。（客户端一个、服务端一个）

      （3）会话ID

      （4）从客户端的密码套件列表中选择的一个密码套件

      （5）从客户端的压缩方法的列表中选择的压缩方法

  - 服务器鉴别与密钥交换
    （1）服务器将数字证书和到根CA整个链发给客户端，使客户端能用服务器证书中的服务器公钥认证服务器，先发送了密钥交换算法对应的加密/解密公钥证书
    （2）服务器密钥交换（可选）：这里视密钥交换算法而定
    （3）证书请求：服务端可能会要求客户自身进行验证

  - 客户机鉴别与密钥交换

    （1）为了对服务器证明自身，客户要发送一个证书信息，可选，在IIS中可以配置强制客户端证书认证

    （2）客户机密钥交换：这里客户端将预备主密钥发送给服务端，使用服务端的公钥进行加密

    （3）证书验证（可选），对预备秘密和随机数进行签名，证明拥有（a）证书的公钥

  - 完成

    ![img](https://img-blog.csdn.net/2018052315035019?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaXBmc2hfc2g=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- 记录协议：在客户机和服务器握手成功后使用，即客户机和服务器鉴别对方和确定安全信息交换使用的算法后，进入SSL记录协议，记录协议向SSL连接提供两个服务：

  - 保密性：使用握手协议定义的秘密密钥实现
  - 完整性：握手协议定义了MAC，用于保证消息完整性

  ![img](https://img-blog.csdn.net/20180523150500822?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaXBmc2hfc2g=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- 警报协议：客户机和服务器发现错误时，向对方发送一个警报消息。如果是致命错误，则算法立即关闭SSL连接，双方还会先删除相关的会话号，秘密和密钥。每个警报消息共2个字节，第1个字节表示错误类型，如果是警报，则值为1，如果是致命错误，则值为2；第2个字节制定实际错误类型