## HTTP 学习

> 影响 HTTP 网络请求的因素主要是：带宽和延迟，关键在低延迟
>
> URI 包括 URL（统一资源定位符，像地址一样） 和 URN（像名字一样）
>
> URI 是 URL 的关键是协议（protocol），如 http://、ftp://
>
> ps. 下面全是 URI，部分是 URL

- 分层
  - 应用层：HTTP
  - 传输层：TCP、UDP
  - 网络层：IP

```http
ftp://ftp.is.co.za/rfc/rfc1808.txt (URL)
http://www.ietf.org/rfc/rfc2396.txt (URL)
ldap://[2001:db8::7]/c=GB?objectClass?one (URL)
mailto:John.Doe@example.com (URL)
news:comp.infosystems.www.servers.unix (URL)
telnet://192.0.2.16:80/ (URL)
tel:+1-816-555-1212
urn:oasis:names:specification:docbook:dtd:xml:4.1.2
```

---

### 一、响应行

- 无错：
  - 1XX：服务端收到请求，需进一步处理才能完成
  - 2XX：收到
  - 3XX：301 永久重定向、302 临时重定向
- 出错：
  - 4XX：客户端出错
    - 400 Bad Request：语法错误导致服务器无法理解请求信息
    - 401 Unauthorized：请求需要验证
    - 403 Forbidden：服务器接受到请求，但拒绝处理
    - 404 Not Found
  - 5XX：服务端出错
    - 500 Internal Server Error：服务器内部错误
    - 502 Bad Gateway：作为网关或者代理工作的服务器拿不到响应
    - 503 Service Unavailable：因为临时文件超载导致服务器不能处理当前请求
    - 504 Gateway Timeout：作为网关或者代理工作的服务器获取响应超时

### 二、HTTP1.0 和 HTTP1.1 的区别

- 长连接

  > HTTP1.1 支持长连接和请求的流水线处理，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少建立和关闭连接的消耗和延迟，在 HTTP1.1 中默认开启长连接

- 节约带宽

  > HTTP1.0 中存在一些浪费带宽的现象，如客户端只需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1 支持只发送 header 信息（不带任何 body 信息），如果服务器认为客户端有权限请求服务器，则返回 100，客户端接收到 100 才开始把请求 body 发送到服务器；如果返回 401，客户端就可以不用发送请求 body 节约带宽

- HOST 域

  > HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此请求消息中的 URL 并没有传递主机名（hostname），HTTP1.0 没有 host 域。而一台物理服务器上可以存在多个虚拟主机，且共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都支持 host 域，且请求消息中如果没有 host 域会报错（400）

- 缓存处理

  > HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 引入更多缓存控制策略例如 Entity tag，If-Unmodified-Since，If-Match，If-None-Match 等缓存头来控制缓存策略

- 错误通知管理

  > HTTP1.1 中新增了 24个 错误状态响应码

#### 1、HTTP 1.1 缺陷

- 高延迟 — 队头阻塞
- 无状态特性 — 阻碍交互：对连接状态无记忆能力，无 cookie 机制
- 明文传输 — 不安全性
- 不支持服务端推送

### 三、HTTPS 和 HTTP 的区别

- HTTPS 协议需要到 CA 申请证书
- HTTP 协议运行在 TCP 之上，传输内容是明文，HTTPS 运行在 SSL/TLS 之上，SSL/TLS 运行在 TCP 之上，传输内容经过加密
- 使用完全不同的连接方式，用的端口也不一样，HTTP 是 80，HTTPS 是 443
- HTTPS 可以有效防止运营商劫持

### 四、SPDY

> HTTP1.x 的优化
>
> SPDY 位于 HTTP 之下，TCP 和 SSL 之上

<img src="\网络\计网图片\SPDY位置.png" alt="SPDY位置" style="zoom: 50%;" />

- 降低延迟

  > 采取多路复用，多个请求共享一个 tcp 连接，解决 HOL blocking（线头阻塞）问题，降低延迟，提高带宽利用率
  >
  > HOL blocking（线头阻塞）：当前 1、3 输入队列是相互竞争，即它们相同的输出端口口 4 发送数据包。如果交换结构决定从输入队列 3 中传输数据包，则在同一时钟周期内不能处理输入队列 1 的数据包。且处于输出队列 1 的后续数据包，如第二个数据包（输出端口为 3，当前空闲）也将无法被输出到端口 3

  ![线头阻塞](C:\Users\13085\Desktop\git_work\网络\计网图片\线头阻塞.png)

  

- 请求优先级

  > SPDY 允许给每个 request 设置优先级，重要请求会优先得到响应。如浏览器加载首页，首页的 html 内容应优先展示，之后才是各种静态资源文件，脚本文件等加载，保证用户第一时间看到网页内容

- header 压缩

  > HTTP1.x 的 header 很多时候是重复多余的。选择合适的压缩算法可以减小包大小和数量

- 基于 HTTPS 的加密协议传输

- 服务端推送

  > 如网页有个 sytle.css 请求，客户端收到 sytle.css 数据时，服务端将 sytle.js 文件推送给客户端，当客户端再次尝试获取 sytle.js 时可以直接从缓存中获取，不用再发请求
  >
  > 普通：
  >
  > <img src="C:\Users\13085\Desktop\git_work\网络\计网图片\普通客户端请求.png" alt="普通客户端请求" style="zoom:67%;" />
  >
  > 服务端推送：
  >
  > <img src="C:\Users\13085\Desktop\git_work\网络\计网图片\服务器推送.png" alt="服务器推送" style="zoom:67%;" />

### 五、HTTP2.0 和 SPDY 的区别

- HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS
- HTTP2.0 消息头的压缩算法采用 HPACK，而非 SPDY 采用的 DEFLATE

### 六、HTTP2.0 和 HTTP1.X 的区别

- 新的二进制格式

  > HTTP1.x 的解析基于文本，存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景很多，二进制只认 0 和 1 的组合，实现方便且健壮

- 多路复用

  > 连接共享，一个 request 对应一个 id，一个连接上可以有多个 request，每个连接的 request 可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。

- header 压缩

  > HTTP1.x 的 header 带有大量信息，每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields 表，避免重复 header 的传输，减小传输大小

- 服务端推送

  > 同 SPDY 一样

### 七、HTTP2.0 多路复用和 HTTP1.X 长连接复用的区别

- HTTP/1.* 一次请求响应，建立一个连接，用完关闭，每一个请求都要建立一个连接
- HTTP/1.1 Pipeling 解决方式：若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞即线头阻塞
- HTTP/2 多个请求可同时在一个连接上并行执行，请求之间不会互相影响

<img src="C:\Users\13085\Desktop\git_work\网络\计网图片\http1、2区别.png" alt="http1、2区别" style="zoom: 67%;" />

#### 1、HTTP2 缺陷

- TCP 以及 TCP+TLS 建立连接的延时
- TCP 的队头阻塞没有彻底解决
- 多路复用导致服务器压力上升
- 多路复用容易 Timeout

### 八、HTTPS

### HTTPS 通信过程和理论基础

####1、密码学基础

- 明文： 未被加密过的原始数据
- 密文：明文被某种加密算法加密之后，会变成密文，确保原始数据的安全。密文也可被解密，得到原始的明文
- 密钥：在明文转换为密文或将密文转换为明文的算法中输入的一种参数。密钥分为对称密钥与非对称密钥，分别应用在对称加密和非对称加密上
- 对称加密（私钥加密）：信息的发送方和接收方使用同一个密钥去加密和解密数据。特点是算法公开、加解密速度快，适合大数据量，常见的对称加密算法有 DES、3DES、TDEA、Blowfish、RC5 和 IDEA

> 加密过程：
> 明文 + 加密算法 + 私钥 => 密文，
> 解密过程：
> 密文 + 解密算法 + 私钥 => 明文，
> 对称加密中用到的密钥叫做私钥，该密钥不能被泄露。其加密过程中的私钥与解密过程中用到的私钥是同一个密钥，这是加密“对称”的原因。由于对称加密的算法公开，一旦私钥泄露，密文就容易被破解，对称加密的缺点是密钥安全管理困难

- 非对称加密（公钥加密）：与对称加密相比，安全性更好。非对称加密使用一对密钥（公钥和私钥），二者成对出现。私钥自己保存，不能对外泄露。公钥是公共的密钥，任何人都可获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密

> 被公钥加密过的密文只能被私钥解密，过程：
> 明文 + 加密算法 + 公钥 => 密文； 密文 + 解密算法 + 私钥 => 明文，
> 被私钥加密过的密文只能被公钥解密，过程：
> 明文 + 加密算法 + 私钥 => 密文； 密文 + 解密算法 + 公钥 => 明文，
> 加解密使用两个不同密钥，这是加密“非对称”的原因。非对称加密的缺点是加解密时间长、速度慢，适合少量数据。非对称加密中的主要算法有：RSA、Elgamal、Rabin、D-H、ECC（椭圆曲线加密算法）等

------

####2、HTTPS通信过程

- HTTPS 协议 = HTTP 协议 + SSL/TLS 协议，在数据传输中，用 SSL/TLS 对数据进行加解密，用 HTTP 对加密后的数据进行传输
- SSL（Secure Sockets Layer，安全套接层协议），是为网络通信提供安全及数据完整性的一种安全协议
- TLS（Transport Layer Security，安全传输层协议），TLS 与 SSL3.0 间存在着显著差别，主要是其支持的加密算法不同，所以 TLS 与 SSL3.0 不能互操作
- HTTPS 为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输

![https通信](C:\Users\13085\Desktop\One_Piece\网络\图片\https通信.png)

- HTTPS 在传输的过程中会涉及到三个密钥：

> 服务器端的公钥和私钥，用来进行非对称加密
>
> 客户端生成的随机密钥，用来进行对称加密

- HTTPS 请求：
  - 客户端向服务器发起 HTTPS 请求，连接到服务器的 443 端口，发送 Client Hello 消息：

    - 一个客户端生成的随机数 Random1
    - 客户端支持的加密套件（Support Ciphers Suites）
    - SSL Version
    - 压缩算法（压缩 Http 头部）等

  - 服务器端接收到 Client Hello 后发送 Server Hello 消息

    - 从客户端传来的消息中确定一种加密套件（决定加密和生成摘要时使用的算法）
    - 生成随机数 Random2（用来创建加密密钥）
    - 如果支持则同意客户端首选的压缩算法
    - 选择客户端支持的 SSL 最新版本

    > 此时客户端知道：
    >
    > SSL 版本、密钥交换、信息验证、加密算法、压缩方法、两个随机数

  - 服务器发送：

    - Certificate 消息（可选）：数字证书和到根 CA 整个链，使客户端能用服务器证书中的**服务器公钥**认证服务器
    - 服务器密钥交换（可选）：在 Client Hello 消息的 Cipher Suite 信息决定密钥交换方式（RSA 或 DH），在此处包含完成密钥交换所需的一系列参数
    - 证书请求（可选）：要求客户自身进行验证，包含服务端支持的证书类型（RSA、DSA、ECDSA）和服务器端信任的所有 CA 列表，客户端用来筛选证书
    - 服务器握手完成：第二阶段的结束，第三阶段开始的信号

  - 客户端接收并解析，发送响应消息：

    - Certificate 消息（可选）：若服务器端要求发送客户端证书则发送，若没有证书发送一个 no_certificate 警告

    - 客户机密钥交换（Pre-master-secret）：根据随机数，按照密钥交换算法算出一个 pre-master（随机数）发送给服务器，服务器端收到后算出 main master（密钥），客户端也能算出 main master，如此双方算出对称密钥。发送过程使用服务器公钥加密，服务器用自己私钥解密（客户端证明自己持有客户端证书私钥）

      > RSA 算法生成一个 48 字节的随机数
      >
      > DH 算法发送客户端 DH 参数

    - 证书验证（可选）：在客户端发送自己证书到服务器端才需发送。包含一个签名，对从第一条消息以来的所有握手消息的 HMAC 值（用密钥）进行签名

  - 客户端发送一个 ChangeCipherSpec 消息（编码改变通知，ChangeCipherSpec 是一个独立协议）

    - 把协商的加密套件拷贝到当前连接状态中
    - 用新算法、密钥参数发送一个 Finished 消息，同时是前面发送的所有内容的 hash 值，检查密钥交换和认证过程是否成功（使用 HMAC 算法计算收到和发送的所有握手消息的摘要，通过 RFC5246 定义的伪函数 PRF 计算出结果，加密后发送）

  - 服务器同样发送 ChangeCipherSpec 消息和 Finished 消息

    - 用私钥解密得 Pre-master 数据，基于两个明文随机数计算得协商密钥
    - 计算之前所有接收信息的 hash 值，解密客户端发送的 hash 值，验证数据和密钥正确性
    - 发送一个 ChangeCipherSpec（告知客户端已经切换到协商过的加密套件状态，准备使用加密套件和 Session Secret 加密数据）
    - 用 Session Secret 加密一段 Finish 消息发送给客户端，验证之前通过握手建立起来的加解密通道是否成功

------

####3、数字证书

- 服务器接收到客户端发来的请求时，会向客户端发送服务器自己的公钥，但黑客有可能中途篡改公钥，将其改成黑客自己的，这时需要用到数字证书
- 想让客户端信赖公钥，公钥要找一个担保人——证书认证中心（Certificate Authority，简称 CA）。CA 是专门对公钥进行认证、担保的公司。 全球知名的 CA 也就 100 多个，都是全球都认可的，比如 VeriSign、GlobalSign 等，国内知名的 CA 有 WoSign
- CA 本身也有一对公钥和私钥，CA 会用自己的私钥对要进行认证的公钥进行非对称加密，此处待认证的公钥就相当于是明文，加密完之后，得到的密文再加上证书的过期时间、颁发给、颁发者等信息，组成数字证书
- 不论什么平台，设备的操作系统中都会内置 100 多个全球公认的 CA，即中存储了这些 CA 的公钥。当客户端接收到服务器的数字证书的时候，会进行如下验证：

> 客户端用设备中内置的 CA 的公钥尝试解密数字证书，如果所有内置的 CA 的公钥都无法解密该数字证书，说明该数字证书不是由一个全球知名的 CA 签发的，这样客户端无法信任该服务器的数字证书
>
> 如果有一个 CA 的公钥能够成功解密该数字证书，说明该数字证书就是由该 CA 的私钥签发的，因为被私钥加密的密文只能被与其成对的公钥解密
>
> 此外还要检查客户端当前访问的服务器的域名是否与数字证书中提供的“颁发给”这一项吻合，还要检查数字证书是否过期等

- 证书链：一般情况下，CA 不会用自己的私钥去直接签名某网站的数字证书，一般 CA 会先签发一种证书，然后用这种证书再去签发百度等的数字证书。如 VeriSign 签发 Symantec 证书，然后 Symantec 又签发baidu.com，VeriSign 位于最顶端，类似根结点，叫做根 CA，Symatec 位于中间，叫做中间 CA，有可能有多个中间CA，这样从根 CA 到中间 CA，再到最终网站的证书，形成一条证书链

### 九、TCP 和 UDP 的区别

- 连接方面区别：TCP 面向连接；UDP 是无连接的，即发送数据之前不需要建立连接
- 安全方面区别：TCP 提供可靠服务，通过 TCP 连接传送的数据，无差错，不丢失，不重复，按序到达；UDP 尽最大努力交付，即不保证可靠交付
- 传输效率区别：TCP 传输效率相对较低；UDP传输效率高，适用于对高速传输和实时性有较高的通信或广播通信
- 连接对象数量区别：TCP连接只能是点到点、一对一；UDP支持一对一、一对多、多对一和多对多的交互通信

> TCP 三次握手：

<img src="C:\Users\13085\Desktop\git_work\网络\计网图片\三次握手.png" alt="三次握手" style="zoom:67%;" />

- 客户端向服务器发出连接请求报文，报文首部中的同步位 SYN=1，同时随机生成初始序列号 seq=x
- 服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中 ACK=1，SYN=1，确认号是 ack=x+1，同时为自己随机初始化一个序列号 seq=y
- 客户进程收到确认后，还要向服务器给出确认。确认报文的 ACK=1，ack=y+1，此时TCP连接建立

> TCP 四次挥手：
>
> - 为什么挥手需要四次：
>
> 挥手阶段中服务端的 ACK 和 FIN 数据包不能合为一次，因为挥手阶段客户端发送 FIN 表示自己发完了，此时客户端到服务端的连接已经释放，客户端不会再发送数据，但服务端还可以继续向客户端发送数据，等到服务端也完成了数据发送，才会发送 FIN，这时客户端回复 ACK 才可以结束通信

<img src="C:\Users\13085\Desktop\git_work\网络\计网图片\四次挥手.png" alt="四次挥手" style="zoom:67%;" />

- 客户端发送一个**FIN(结束)**，用来关闭客户到服务端的连接，FIN=1，其序列号为 seq=u
- 服务端收到 FIN，发回一个**ACK(确认)**，确认收到序号为收到序号 +1，ACK=1，ack=u+1，并且带上自己的序列号 seq=v
- 服务端发送一个**FIN(结束)**到客户端，服务端关闭客户端的连接。FIN=1，ack=u+1
- 客户端发送**ACK(确认)**报文确认，并将确认的序号+1，关闭完成。ACK=1，ack=w+1，序列号是 seq=u+1

> 流量控制

> 拥塞控制

### 十、HTTP3 QUIC

<img src="C:\Users\13085\Desktop\git_work\网络\计网图片\http1、2、3.jpg" alt="http1、2、3" style="zoom: 50%;" />

> 基于 UDP，真正解决了队头阻塞问题

#### 1、机制

- 自定义连接机制

  > 一条 tcp 连接由四元组标识，分别是源 ip、源端口、目的端口，一个元素发生变化时就会断开重连，再次进行三次握手，导致一定的延时
  >
  > UDP 可以在 QUIC 的逻辑里维护连接机制，不再以四元组标识，而是以一个 64 位的随机数作为 ID 标识，且 UDP 无连接，当 ip 或端口变化时，只要 ID 不变，就不需重新建立连接

- 自定义重传机制

  > tcp 为保证可靠性，通过使用序号和应答机制，来解决顺序问题和丢包问题，任一序号包发过去，都要在一定时间内得到应答，超时就会重发这个序号的包，通过自适应重传算法（通过采样往返时间 RTT 不断调整）
  >
  > 但在 TCP 里面超时的采样存在不准确的问题。如发送一个包，序号 100，没有返回，再发送一个 100，过一阵返回 ACK101，客户端收到了，但往返时间没法计算（是 ACK 到达的时候减去第一还是第二？）
  >
  > QUIC 也有序列号，是递增的，任何序列号的包只发送一次，下次就加 1，使计算准确
  >
  > QUIC 定义一个 offset 概念。QUIC 是面向连接的，是一个数据流，发送的数据在这个数据流里有个偏移量 offset，可通过 offset 查看数据发送到了哪里，只有这个 offset 的包没有来，就要重发。如果来了，按照 offset 拼接，还是能够拼成一个流。

![image](http://www.chenjinxinlove.com/cdn/offsetbbb.png)

- 无阻塞的多路复用

  > 同 HTTP2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求，但 QUIC 基于 UDP，一个连接上的多个 stream 之间没有依赖。假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的包需要重传，但 stream3 包无需等待就可发给用户

- 自定义流量控制

  > TCP 的流量控制是通过滑动窗口协议，QUIC 的流量控制也是。但 QUIC 窗口适应自己的多路复用机制，不但在一个连接上控制窗口，还在一个连接中的每个 steam 控制窗口
  >
  > TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个序列号，说明前面的都到了，使用前面的没到，后面的到了也不能 ACK，导致后面的到了也有可能超时重传，浪费带宽
  >
  > QUIC 的 ACK 基于 offset，每个 offset 的包来了，进了缓存就可应答，应答后就不会重发，中间的空档会等待到来或重发，窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口的大小，更加准确
